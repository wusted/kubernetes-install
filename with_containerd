Building a Kubernetes Cluster with Kubeadm

1. ON BOTH CONTROL PLANE(MASTER) AND WORKER NODES

Install Packages
Log into the Control Plane Node (Note: The following steps must be performed on all three nodes.).
Create configuration file for containerd:
cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF

Load modules:
sudo modprobe overlay
sudo modprobe br_netfilter

Set system configurations for Kubernetes networking:
cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF

Apply new settings:
sudo sysctl --system

Remove any container runtime that may cause conflict in dependencies:
dnf remove runc docker containerd podman

Add the Docker repo and install Docker:
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

Install containerd:
sudo dnf install -y containerd

Create default configuration file for containerd:
sudo mkdir -p /etc/containerd

Generate default containerd configuration and save to the newly created default file:
sudo containerd config default | sudo tee /etc/containerd/config.toml

Edit config.toml to enable systemd cgroup driver for container d
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml

Restart containerd to ensure new configuration file usage:
sudo systemctl restart containerd

Verify that containerd is running.
sudo systemctl status containerd

Disable swap:
sudo swapoff -a

Disable swap on startup in /etc/fstab:
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

Add Kubernetes to repository list:
cat << EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
repo_gpgcheck=0
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
  https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

Install Kubernetes packages (Note: If you get a dpkg lock message, just wait a minute or two before trying the command again):
sudo dnf install -y kubelet kubeadm kubectl

Turn off automatic updates:
sudo dnf install -y python3-dnf-plugin-versionlock
sudo dnf versionlock add kubeadm kubectl kubelet
sudo dnf versionlock list

Enable the kubelet service. The kubelet service will fail to start until the cluster is initiliazed:
systemctl enable kubelet

2. ONLY ON THE CONTROL PLANE(MASTER NODE)
Initialize the Cluster
Initialize the Kubernetes cluster on the control plane node using kubeadm
sudo kubeadm init --pod-network-cidr 10.244.0.0/16

IMPORTANT, COPY(DISPLAY THE "kubeadm join" command displayed it will be needed later)

Set kubectl access:
sudo su - k8s
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

CHOOSE BETWEEN FLANNEL(SIMPLE) OR CALICO(POLICY-BASED) CNI Network Providers

On the Control Plane Node, Deploy Flannel:
kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml

OR

On the Control Plane Node, deploy Calico:
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml


Check status of the control plane node:
kubectl get nodes

Join the Worker Nodes to the Cluster
In the Control Plane Node, create the token and copy the kubeadm join command (NOTE:The join command can also be found in the output from kubeadm init command):
kubeadm token create --print-join-command

In both Worker Nodes, paste the kubeadm join command to join the cluster. Use sudo to run it as root:
sudo kubeadm join ...

In the Control Plane Node, view cluster status (Note: You may have to wait a few moments to allow all nodes to become ready):
kubectl get nodes

