Building a Kubernetes Cluster with Kubeadm

1. ON BOTH CONTROL PLANE(MASTER) AND WORKER NODES

Install Packages
Log into the Control Plane Node (Note: The following steps must be performed on all three nodes.).
Create configuration file for containerd:
cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF

Load modules:
sudo modprobe overlay
sudo modprobe br_netfilter

Set system configurations for Kubernetes networking:
cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF

Apply new settings:
sudo sysctl --system

Remove any container runtime that may cause conflict in dependencies:
dnf remove runc docker containerd podman

Add the Docker repo and install Docker:
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

Install containerd:
sudo dnf install -y containerd

Create default configuration file for containerd:
sudo mkdir -p /etc/containerd

Generate default containerd configuration and save to the newly created default file:
sudo containerd config default | sudo tee /etc/containerd/config.toml

Edit config.toml to enable systemd cgroup driver for container d
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml

Restart containerd to ensure new configuration file usage:
sudo systemctl enable containerd
sudo systemctl restart containerd

Verify that containerd is running.
sudo systemctl status containerd

Disable swap:
sudo swapoff -a

Disable swap on startup in /etc/fstab:
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

Add Kubernetes to repository list:
cat << EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
repo_gpgcheck=0
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
  https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

Install Kubernetes packages (Note: If you get a dpkg lock message, just wait a minute or two before trying the command again):
sudo dnf install -y kubelet kubeadm kubectl

Turn off automatic updates:
sudo dnf install -y python3-dnf-plugin-versionlock
sudo dnf versionlock add kubeadm kubectl kubelet
sudo dnf versionlock list

Enable the kubelet service. The kubelet service will fail to start until the cluster is initiliazed:
sudo systemctl enable kubelet

FIREWALL RULES:
Disable firewalld:
sudo systemctl stop firewalld
sudo systemctl disable firewalld

OR 

ON CONTROL PLAN(MASTER) NODE:
firewall-cmd --permanent --add-port=6443/tcp
firewall-cmd --permanent --add-port=2379-2380/tcp
firewall-cmd --permanent --add-port=10250/tcp
firewall-cmd --permanent --add-port=10259/tcp
firewall-cmd --permanent --add-port=10257/tcp
firewall-cmd --permanent --add-port=10255/tcp
firewall-cmd --permanent --add-port=8472/udp
firewall-cmd --permanent --add-port=8285/udp
firewall-cmd --add-masquerade --permanent
firewall-cmd --reload
systemctl restart firewalld

ON WORKER NODES:
firewall-cmd --permanent --add-port=10250/tcp
firewall-cmd --permanent --add-port=10255/tcp
firewall-cmd --permanent --add-port=8472/udp
firewall-cmd --permanent --add-port=8285/udp
firewall-cmd --permanent --add-port=30000-32767/tcp
firewall-cmd --add-masquerade --permanent
systemctl restart firewalld

2. ONLY ON THE CONTROL PLANE(MASTER) NODE
Initialize the Cluster
Initialize the Kubernetes cluster on the control plane node using kubeadm
sudo kubeadm init --pod-network-cidr 10.244.0.0/16

IMPORTANT, COPY(DISPLAY THE "kubeadm join" command displayed it will be needed later)

Set kubectl access:
sudo su - k8s
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

CHOOSE BETWEEN FLANNEL(SIMPLE) OR CALICO(POLICY-BASED) CNI Network Providers

All the following with k8s user

On the Control Plane Node, Deploy Flannel:
kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml

OR

On the Control Plane Node, deploy Calico:
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml


Join the Worker Nodes to the Cluster
In the Control Plane Node, create the token and copy the kubeadm join command (NOTE:The join command can also be found in the output from kubeadm init command):
kubeadm token create --print-join-command

3. ONLY ON ALL WORKER NODE
Paste the kubeadm join command to join the cluster. Use sudo to run it as root:
sudo kubeadm join ...

4. ON BOTH CONTROL PLANE(MASTER) AND WORKER NODES
Start kubelet service. For nodes to communicate with API Server
sudo systemctl start kubelet

5. ONLY ON CONTROL PLANE(MASTER) NODE
In the Control Plane Node, view cluster status (Note: You may have to wait a few moments to allow all nodes to become ready):
kubectl get nodes
kubectl get pods --all-namespaces


REFERENCES:
https://kubernetes.io/docs/setup/production-environment/container-runtimes/
https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/
